---
title: "Comparing the Effectiveness of Treatment for Post-Traumatic Stress Disorder (PTSD) in Veterans and Non-Veterans" 
subtitle: "Promotion Research of Kirsten Reij"
author: "Ernst-Paul Swens, [Swens Data Science](https://ernst-paul.github.io/)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
   html_document:
      toc: yes
      toc_depth: 2
      toc_float: yes
---

<style type="text/css">
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 14px;
    border-left: 5px solid #eee;
}
</style>

--- 

# 1. Data Preperation

We examined the data prior to conducting any statistical analysis. We started by reformatting and re-coding variables, followed by a matching procedure. Lastly, we present the descriptive statistics of the matched dataset.

---

## 1.1. Data Inspection

The following `R` packages were utilized.

```{r message=FALSE, warning=FALSE, include=TRUE}
library(lubridate)   # package to help calculate age of patients
library(tableone)    # package to help create descriptive table
library(magrittr)    # package to add additional pipe options
library(labelled)    # package to help with labeling columns
library(MatchIt)     # package for the matching procedure
library(ggplot2)     # package for creating fancy plots
library(ggpubr)      # package to combine fancy plots
library(table1)      # package to create table one
library(tidyr)       # package to make life easier
library(dplyr)       # package to make life easier
```

We performed feature reduction on the raw data, retaining only the variables `veteran`, `starting_date`, `age`, `sex`, `pre_score`, `post_score`, `pre_diagnosis`, `post_diagnosis` and `duration`. We re-coded the variables `veteran`, `starting_date`, and `age`. We created a missingness indicator `follow_up_miss` for the follow-up treatment score. There was one veteran removed without the pre-treatment diagnosis of PTSD.

| **Variable**        | **Explanation**                           | **Coding**                  |
|:--------------------|:------------------------------------------|:----------------------------|
| `veteran`           | being a veteran                           | factor                      |
| `starting_date`     | date start treatment                      | date                        |
| `sex`               | sex of patient                            | factor                      |
| `age`               | age of patient                            | continuous                  |
| `pre_score`         | pre-treatment CAPS score                  | continuous                  |
| `post_score`        | post-treatment CAPS score                 | continuous                  |
| `follow_up_miss`    | missingness indicator for follow-up score | factor                      |
| `pre_diagnosis`     | diagnosis of PTSD pre-treatment           | factor                      |
| `post_diagnosis`    | diagnosis of PTSD post-treatment          | factor                      |
| `duration`          | treatment duration                        | factor                      |

```{r eval=FALSE, warning=FALSE, include=TRUE}
# set seed to make results reproducible
set.seed(123)

# read in data
data <- read.csv("data/data_raw.csv")

# include a unique id
data <- data %>% dplyr::mutate(id = row_number()) 

# select relevant columns, clean dates, list-wise omit missing data 
vet <- data %>%
  dplyr::select(IsVeteraan, id) %>%
  dplyr::mutate(
    veteran           = as.factor(IsVeteraan),
    sex               = data$geslacht,
    starting_date     = as.Date(data$StartDatum, "%Y-%m-%d"),
    age               = trunc((as.Date(data$geboortedatum, "%Y-%m-%d") 
                          %--% Sys.Date()) / years(1)),
    pre_score         = data$CAPS5Score_IN,
    post_score        = data$CAPS5Score_TK,
    follow_up_miss    = !is.na(data$CAPS5Score_FU),
    pre_diagnosis     = factor(
      data$diagnose_IN, 
      levels = c(0, 1), 
      labels = c("No PTSD", "PTSD")),
    post_diagnosis    = factor(
      data$diagnose_TK, 
      levels = c(0, 1), 
      labels = c("No PTSD", "PTSD")),
    duration          = factor(
      data$BEHDAGEN_GEPLAND > 7, 
      levels = c(TRUE, FALSE), 
      labels = c("8 days or more", "Less than 8 days"))) %>%
  dplyr::select(-IsVeteraan) %>%
  dplyr::filter(id != 47) %>%
  dplyr::filter(pre_diagnosis == "PTSD") %>%
  na.omit()
```

---

## 1.2. Matching

Before making statistical inferences, we took into account the class imbalance of `veteran` and the potential confounding effects of `age`, `sex`, and `duration`.

```{r eval=FALSE, include=FALSE}
# compute standardized mean difference
table_1 <- CreateTableOne(
   vars = c("sex", "age", "duration"), 
   strata = "veteran", 
   data = vet, 
   test = TRUE)

# save data for table 1 
save(table_1, file = "data/cache/table_1.RData")
```

```{r echo=FALSE}
# load data for table 1 
load("data/cache/table_1.RData")

# load data 
print(table_1, smd = TRUE)
```

We noticed a significant class imbalance with only 43 veterans and 3848 non-veterans. We should be careful with the confounding effect of `age` and `sex`, as both standardized mean differences are greater than 0.5. Therefore, we used a nearest neighbor matching procedure. The algorithm matched each veteran with the most similar non-veteran based on `sex`, `age`, `starting_date`, and `duration`.

```{r eval=FALSE, warning=FALSE, include=TRUE}
# matching non-veterans 
match <- matchit(
   veteran ~ sex + age + starting_date + duration, 
   method = "nearest",
   data = vet)

# matched data frame
vet <- rbind(vet[match[["match.matrix"]],], dplyr::filter(vet, veteran == 1))
```

After the matching procedure, we observed a significant decrease in the standardized mean difference. This suggests that the matching procedure was successful in controlling the confounding effects of `age`, `sex`, and `duration`.

```{r eval=FALSE, include=FALSE}
# compute standardized mean difference 
table_2 <- CreateTableOne(
   vars = c("sex", "age", "duration"), 
   strata = "veteran",
   data = vet, 
   test = TRUE)

# save data for table 2
save(table_2, file = "data/cache/table_2.RData")
```

```{r echo=FALSE}
# load data for table 2
load("data/cache/table_2.RData")

# load data 
print(table_2, smd = TRUE)
```
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
sd_pooled <- sqrt((
  sd(vet$pre_score[vet$veteran == "0"])^2 +
  sd(vet$pre_score[vet$veteran == "1"])^2 +
  sd(vet$post_score[vet$veteran == "0"])^2 +
  sd(vet$post_score[vet$veteran == "1"])^2) / 4)

sem <- sqrt(2 * sd_pooled * sqrt(1 - 0.93))^2
```

```{r include=FALSE}
sem <- 6.762459
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# store processed data
vet <- vet %>%
   left_join(
      data %>% 
         dplyr::select(
            LEC_10, LEC_8, LEC_6, LEC_1, LEC_2, LEC_3, LEC_4, 
            depressie_IN, dysthymie, enkelfob, GAS, HYP, OCD, 
            pan, ago, soc, socgegen, sui, id), 
      by = "id") %>% 
   dplyr::mutate(id = row_number()) %>%
   dplyr::mutate(
      sex      = factor(sex, levels = c(1, 2), labels = c("Male", "Female")),
      veteran  = factor(veteran, labels = c("Non-Veteran", "Veteran")),
      war      = factor(LEC_10,   levels = c(0, 1), labels = c("No", "Yes")),
      sexual   = factor(LEC_8,    levels = c(0, 1), labels = c("No", "Yes")),
      physical = factor(LEC_6,    levels = c(0, 1), labels = c("No", "Yes")),
      nature   = as.numeric(LEC_1 | LEC_2 | LEC_3 | LEC_4),
      nature   = factor(nature, levels = c(0, 1), labels = c("No", "Yes")),
      mood     = as.numeric(depressie_IN %in% c(1,2,3,7) | dysthymie %in% 1),
      mood     = factor(mood, levels = c(0, 1), labels = c("No", "Yes")),
      fear     = as.numeric(
         enkelfob %in% c(1) | GAS %in% c(1, 2) | 
         HYP %in% c(1) | OCD %in% c(1, 2, 3) | pan %in% c(1, 2, 3, 4, 5) | 
         ago%in% c(1) | soc%in% c(1) | socgegen%in% c(1)),
      fear = factor(fear, levels = c(0, 1), labels = c("No", "Yes")),
      suicide = factor(
         sui, 
         levels = c(0, 1, 2, 3), 
         labels = c("None", "Low", "Medium", "High")),
      diff_score = post_score - pre_score,
      rci = ifelse(diff_score / sem >  1.96, "1", "2"),
      rci = ifelse(diff_score / sem < -1.96, "3", rci),
      rci = factor(rci, levels = c("1", "2", "3"), 
      labels = c("Deteriorated", "Unchanged", "Improved"))) %>% 
   dplyr::select(
      -c(LEC_10, LEC_8, LEC_6, LEC_1, LEC_2, LEC_3, LEC_4, 
      depressie_IN, dysthymie, enkelfob, GAS, HYP, OCD, 
      pan, ago, soc, socgegen, sui)) %>%
   set_variable_labels(
      sex = "Sex",
      veteran = "Veteran",
      war = "War violence",
      sexual = "Sexual violence",
      physical = "Physical violence", 
      nature = "Natural disasters and serious accidents",
      mood = "Mood disorders",
      fear = "Anxiety disorders",
      suicide = "Suicide risk",
      duration = "Treatment duration",
      pre_score = "Pre-treatment CAPS score",
      post_score = "Post-treatment CAPS score",
      age = "Age",
      id = "Patient id",
      starting_date = "Treatment starting date",
      follow_up_miss = "Missingness indicator follow-up",
      pre_diagnosis = "PTSD diagnosis pre-treatment",
      post_diagnosis = "PTSD diagnosis post-treatment",
      diff_score = "Difference post and pre-score",
      rci = "Reliable change index")

# export dataframe to rdata and csv
save(vet, file = "data/data_processed.RData")
write.csv(vet, file = "data/data_processed.csv", row.names = FALSE)
```

```{r include=FALSE}
load("data/data_processed.RData")
```

---

## 1.3. Patient Characteristics

The following table presents the patient characteristics.

```{r echo=FALSE}
p_value <- function(x, ...) {
  x <- x[c("Veteran", "Non-Veteran")]
  y <- unlist(x)
  g <- factor(rep(1:length(x), times = sapply(x, length)))
  
  if (is.numeric(y)) p <- t.test(y ~ g)$p.value 
  else p <- chisq.test(table(y, g), simulate.p.value = TRUE)$p.value
  
  c("", sub("<", "&lt;", format.pval(p, digits=3, eps=0.001)))
}

table1::table1(
  ~ sex + pre_score + post_score + diff_score + age + war + sexual + physical + 
    nature + mood + fear + suicide + duration | veteran, 
  data = vet, 
  topclass = "Rtable1-zebra", 
  overall = c(left = "Total"),
  extra.col=list(`p-value` = p_value))
```

<br>

> **About Including p-values in Table 1**
>
> Including p-values in Table 1 may be easy, but it is not recommended. This is true whether the data is from an observational study or a randomized trial. If p-values are included to show crude associations between predictors and outcomes, they may not be relevant as adjusted assessments from regression analysis are usually more important. Including p-values in Table 1 to show differences in participant characteristics between exposure groups is not useful. What matters for confounding is the magnitude of differences in the sample, not if the groups differ in the population (as tested by p-values).

---

# 2. Missing Data in Follow-Up

There are 46 veterans records in total, with one being a re-registration and another without PTSD diagnosis. Excluding these records, there are 45 veterans. Of those 45, 43 have a CAPS score after treatment and 23 have a follow-up CAPS score. The next section examines whether there are any differences between veterans who have a follow-up CAPS score and those who do not.

## 2.1. Missing Data Mechanisms

First, we will explain some technical terms. Then, we will give a more understandable explanation.

The variable $R$ represents whether or not a follow-up CAPS score is missing, where $R = 0$ represents a missing score and $R = 1$ represents a known score. The distribution of $R$ may depend on the data, represented by $Y$. This data may contain complete and missing information, represented by $Y = (Y_{obs}, Y_{mis})$. The missing data may be due to either design or circumstance, such as a forgotten confounding variable. The parameter of the missing data model is represented by $\psi$, and the general expression of the missing data model is $P(R=0|Y_{obs}, Y_{mis},\psi)$, which expresses the probability that the follow-up score is missing, given the observed and missing data, and the parameter of the missing data model.

We can now formulate the hypothesis that:

$$H_0: P(R=0|Y_{obs}, Y_{mis},\psi)=P(R=0|\psi).$$
This implies that the observations with missing follow-up scores are a random subset of all observations, determined by $\psi$. Therefore, there are no systematic differences between the missing and observed follow-up scores. This is known as missing completely at random (MCAR).

The alternative hypothesis is formulated as:

$$H_1: P(R=0|Y_{obs}, Y_{mis},\psi) \ne P(R=0|\psi)$$
This means that the observations with missing follow-up scores are not a random subset of all observations. The missingness may depend on another observed variable, such as veterans with higher pre-treatment scores being less likely to be lost to follow-up. This is known as a missing at random (MAR) mechanism. If the missingness depends on something that was not measured, it is called missing not at random (MNAR). 

It is not possible to definitively distinguish between MCAR, MAR, and MNAR based on the data alone. However, by analyzing the standardized mean differences between the two groups, we can infer which mechanism is most likely to be the cause of missing data. If the standardized mean differences are small, it suggests that the missing data is likely MCAR. If the standardized mean differences are larger, it suggests that the missing data may be MAR or MNAR.

---

## 2.2. Exploration

```{r echo=FALSE}
vet %>% 
  dplyr::filter(veteran == "Veteran") %>%
  CreateTableOne(
    vars = c("age", "duration", "pre_score", "diff_score"), 
    strata = "follow_up_miss", 
    data = ., 
    test = TRUE) %>%
  print(smd=TRUE)
```
There are minimal variations between the groups as indicated by the SMD being less than 0.5. This is also supported by the figure which shows that the distributions of the groups overlap nicely.

```{r echo=FALSE, fig.height=9, fig.width=9, dpi=300, out.width="80%", fig.align="center"}
plot_histogram <- function(x, x_label) {
  vet %>%
  dplyr::filter(veteran == "Veteran") %>%
  ggplot(aes(!!sym(x), color = follow_up_miss, fill = follow_up_miss)) +
  geom_histogram(alpha = 0.5, bins = 10, position = "identity") +
  labs(x = x_label, y = "Count") +
  scale_fill_manual(
    name  = "Follow Up", 
    labels = c("Missing", "Complete"),
    values = c("#D95319", "#0072BD")) + 
  scale_color_manual(
    name = "Follow Up", 
    labels = c("Missing", "Complete"),
    values = c("#D95319", "#0072BD")) + 
  theme_bw() +
  theme(aspect.ratio = 1)
}

plot_list <- list(
  plot_histogram("age", "Age [years]"),
  plot_histogram("pre_score", "Pre-treatment CAPS score"),
  plot_histogram("post_score", "Post-treatment CAPS score"),
  plot_histogram("diff_score", "Difference pre and post-treatment CAPS score")
) 

ggarrange(plotlist = plot_list, ncol = 2, nrow = 2, common.legend = TRUE)

ggsave("figures/missingness.pdf", width = 9, height = 9, dpi = 300)
ggsave("figures/missingness.png", width = 9, height = 9, dpi = 300)
```

In conclusion, the reason for the missing follow-up score appears to be random, supporting the assumption that $H_0$ is true.

# 3. Marginal Analysis

In this chapter, we investigate the effectiveness of the treatment for both veterans and non-veterans by examining the pre- and post-treatment scores. The figure presents the CAPS scores for both groups, which show a decrease in the CAPS scores. Note, the error bars in the figure below shows the 95% confidence interval of the paired t-test. The following sections will determine if this decrease is statistically significant and clinically meaningful.

```{r echo=FALSE, fig.height=4, fig.width=9, dpi=300}
vet %>% 
  pivot_longer(c(pre_score, post_score), names_to = "score") %>%
  dplyr::mutate(score = as.factor(score)) %>%
  Rmisc::summarySEwithin(
      measurevar= "value", 
      withinvars = "score", 
      betweenvars = "veteran",
      idvar= "id", 
      conf.interval= 0.95
   ) %>% 
   ggplot(aes(x=score, y=value, group=veteran)) + 
      geom_errorbar(
         width = 0.1, 
         color = "#A4A4A4",
         aes(ymin = value - ci, ymax = value + ci, color = veteran)) +
      geom_point(
         aes(color = veteran)) + 
      geom_line(aes(linetype = veteran, color = veteran)) +
      facet_grid(~veteran) + 
      theme_bw() +
      theme(legend.position = "none") + 
      scale_x_discrete(
         limits=c("pre_score", "post_score"), 
         labels=c("Pre-treatment", "Post-treatment")) +
      labs(x = "Measurement", y = "Mean total CAPS score") +
      scale_y_continuous(n.breaks = 10, limits = c(0, 80)) + 
      scale_color_manual(
         name = "", 
         values = c("#0072BD", "#D95319")) + 
      scale_shape_manual(
         name = "", 
         values = c(16, 17)) + 
      scale_linetype_manual(
         name = "", 
         values = c(1, 1)) +
      theme(aspect.ratio = 1)

ggsave("figures/paired_t_test.pdf", width = 9, height = 4, dpi = 300)
ggsave("figures/paired_t_test.png", width = 9, height = 4, dpi = 300)
```

## 3.1. Veterans

For the veteran group, the following hypotheses can be formulated:

- Null Hypothesis ($H_0$): The treatment has no effect on the CAPS score. This is represented by the difference between the pre-treatment and post-treatment scores being greater than or equal to zero ($CAPS_{post} - CAPS_{pre} \ge 0$).

- Alternative Hypothesis ($H_1$): The treatment does decrease the CAPS score. This is represented by the difference between the pre-treatment and post-treatment scores being less than zero ($CAPS_{post} - CAPS_{pre} < 0$).

These hypotheses can be tested using a paired t-test. The effect size can be quantified by Cohen's distance. 

```{r echo=FALSE}
t_test <- vet %>% 
   filter(veteran == "Veteran") %$%
   t.test(
      post_score, pre_score, 
      alternative = "less",
      paired = TRUE
   )

t_test
```
The results from the pre-test (M = `r filter(vet, veteran == "Veteran")[, "pre_score"] %>% mean() %>% round(1)`, SD = `r filter(vet, veteran == "Veteran")[, "pre_score"] %>% sd() %>% round(1)`) and post-test (M = `r filter(vet, veteran == "Veteran")[, "post_score"] %>% mean() %>% round(1)`, SD = `r filter(vet, veteran == "Veteran")[, "post_score"] %>% sd() %>% round(1)`) CAPS interview indicate that the treatment significantly reduced symptoms of PTSD in veterans with war-related trauma, t(`r t_test[["parameter"]][["df"]]`) = `r t_test[["statistic"]][["t"]] %>% round(1)`, p `r ifelse(t_test[["p.value"]] < 0.001, "< 0.001", cat("=", t_test[["p.value"]] %>% round(2)))`.

```{r echo=FALSE}
cohen_d <- vet %>% 
   filter(veteran == "Veteran") %$%
   effsize::cohen.d(pre_score, post_score)

cohen_d
```

The effect size for this analysis (d = `r cohen_d$estimate %>% round(2)`) was found to exceed Cohen’s (1988) convention for a large effect (d = .80).

## 3.2. Non-Veterans

For the non-veteran group, the following hypotheses can be formulated:

- Null Hypothesis ($H_0$): The treatment has no effect on the CAPS score. This is represented by the difference between the pre-treatment and post-treatment scores being greater than or equal to zero ($CAPS_{post} - CAPS_{pre} \ge 0$).

- Alternative Hypothesis ($H_1$): The treatment does decrease the CAPS score. This is represented by the difference between the pre-treatment and post-treatment scores being less than zero ($CAPS_{post} - CAPS_{pre} < 0$).

These hypotheses can be tested using a paired t-test. The effect size can be quantified by Cohen's distance. 

```{r echo=FALSE}
t_test <- vet %>% 
   filter(veteran == "Non-Veteran") %$%
   t.test(
      post_score, pre_score, 
      alternative = "less",
      paired = TRUE
   )

t_test
```
The results from the pre-test (M = `r filter(vet, veteran == "Non-Veteran")[, "pre_score"] %>% mean() %>% round(1)`, SD = `r filter(vet, veteran == "Non-Veteran")[, "pre_score"] %>% sd() %>% round(1)`) and post-test (M = `r filter(vet, veteran == "Non-Veteran")[, "post_score"] %>% mean() %>% round(1)`, SD = `r filter(vet, veteran == "Non-Veteran")[, "post_score"] %>% sd() %>% round(1)`) CAPS interview indicate that the treatment significantly reduced symptoms of PTSD in veterans with war-related trauma, t(`r t_test[["parameter"]][["df"]]`) = `r t_test[["statistic"]][["t"]] %>% round(1)`, p `r ifelse(t_test[["p.value"]] < 0.001, "< 0.001", cat("=", t_test[["p.value"]] %>% round(2)))`.

```{r echo=FALSE}
cohen_d <- vet %>% 
   filter(veteran == "Veteran") %$%
   effsize::cohen.d(pre_score, post_score)

cohen_d
```

The effect size for this analysis (d = `r cohen_d$estimate %>% round(2)`) was found to exceed Cohen’s (1988) convention for a large effect (d = .80).

# 4. RCI

The Reliable Change Index (RCI) is a statistical tool used to determine whether a change in a test score is meaningful or simply due to random measurement error. The RCI takes into account the reliability of the measure, the variability in the obtained scores in the group, and the change in the individual's score and yields a pseudo–z-statistic. It is important to note that the RCI is only a rough estimate of the meaningfulness of a change and does not guarantee that a change is real or significant.

```{r echo=FALSE, fig.height=4, fig.width=9, dpi=300}
vet %>%
   ggplot(aes(x = pre_score, y = post_score)) +
      geom_point(aes(color = rci, shape = post_diagnosis)) + 
      geom_abline(aes(
         intercept = 0, 
         slope = 1, 
         linetype = "1")) +
      geom_abline(aes(
         intercept = sem * 1.96, 
         slope = 1, 
         linetype = "2")) + 
      geom_abline(aes(
         intercept = -sem * 1.96, 
         slope = 1, 
         linetype = "2")) + 
      xlim(0, 80) + 
      ylim(0, 80) +
      facet_grid(~veteran) + 
      theme_bw() +
      scale_linetype_manual(
         name = "Boundaries",
         values = c("solid", "dotted"),
         labels = c(
            "No change", "Reliable change 95% CI", "Criteria")) + 
      scale_color_manual(
         name = "RCI",
         values = c("#D95319", "#0072BD", "#77AC30")) +
      scale_shape_manual(
         name = "Diagnosis",
         values = c(1, 4)) +
      xlab("Pre-treament CAPS score") + 
      ylab("Post-treament CAPS score") + 
      theme(aspect.ratio = 1)

ggsave("figures/reliable_change_index.pdf", width = 9, height = 4, dpi = 300)
ggsave("figures/reliable_change_index.png", width = 9, height = 4, dpi = 300)
```

We computed the RCI using a test-retest reliability of 0.73 and the pooled standard deviations of the test scores. A patient was considered to have improved if the CAPS score decreased with `r round(sem * 1.96, 2)` points. From the figure it is interesting to observe that for the non-veterans improvement and no PTSD diagnosis post-treatment appear to coincide, whereas this is not the case for veterans. There are veterans that did improve on their scores, but remained with the PTSD diagnosis post-treatment. 

In the veteran group compared to the non-veteran group, more participants improved and less participants remained unchanged according to the RCI. In the non-veteran group, two people deteriorated. 

```{r echo=FALSE}
table(vet$veteran, vet$rci)
```

However, if we look at the diagnosis of PTSD post-treatment, we observe equal numbers. 

```{r echo=FALSE}
table(vet$veteran, vet$post_diagnosis)
```

# 5. Group Differences 

This chapter explores if there exists a difference in treatment response between the veterans and non-veterans. 

## 5.1. Analysis

Simply put, the Bayesian ANCOVA quantifies how likely the data comes from one the presented models below.

```{r echo=FALSE, fig.align="center", fig.height=4, fig.width=9, message=FALSE, warning=FALSE, dpi=300}
list(
  vet %>%
    ggplot(aes(x = pre_score, y = post_score)) +
    geom_point() + 
    geom_smooth(method="lm", formula= y ~ x, se = FALSE, fullrange = TRUE) + 
    theme_bw() + 
    xlim(0, 80) + 
    ylim(0, 80) +
    xlab("Pre-treament CAPS score") + 
    ylab("Post-treament CAPS score") + 
    ggtitle("Pre-treatment") + 
    theme(aspect.ratio = 1),
  vet %>%
    ggplot(aes(x = pre_score, y = post_score, color = veteran)) +
    geom_point() + 
    geom_smooth(method="lm", formula= y ~ x, se = FALSE, fullrange = TRUE) + 
    theme_bw() + 
    xlim(0, 80) + 
    ylim(0, 80) +
    xlab("Pre-treament CAPS score") + 
    ylab("Post-treament CAPS score") + 
    ggtitle("Pre-treatment and Veteran") + 
    scale_color_manual(name = "", values = c("#0072BD", "#D95319")) +
    theme(aspect.ratio = 1)) %>%
ggarrange(
  plotlist = ., 
  ncol = 2, 
  nrow = 1,
  common.legend = TRUE)

ggsave("figures/models.pdf", width = 9, height = 4, dpi = 300)
ggsave("figures/models.png", width = 9, height = 4, dpi = 300)
```

The following tables present the ANCOVA results.

| Model Comparison      |        |              |        |           |         |
|-----------------------|--------|--------------|--------|-----------|---------|
| **Models**            | $P(M)$ | $P(M\|data)$ | $BF_M$ | $BF_{10}$ | error % |
| Null model            |  0.500 |     0.775    |  3.445 |   1.000   |         |
| Veteran               |  0.500 |     0.225    |  0.290 |   0.290   |  0.967  |

**Note** All models include pre-score 

Only the null model had their model odds $P(M\|data)$ increased after observing the data. The null model was most probable, and to the Veteran model using the Bayes Factor $BF_{10}$. The data are `r round(1.000/0.290, 2)` times more likely under the null model than the veteran model. Or in other words, it is `r round(1.000/0.290, 2)` times more likely that group membership has no effect on treatment success. 

From the model averaged posterior summary, we can observe that the 95% credible interval of both levels of the veteran effect contains the value zero. This also supports that there is no effect of group membership on the effectiveness of treatment. 

| Model Averaged Posterior Summary |             |          |        |                  |                  |
|----------------------------------|-------------|----------|--------|------------------|------------------|
| **Variable**                     | **Level**   | **Mean** | **SD** | **95% CI Lower** | **95% CI Upper** |
| Intercept                        |             |  15.803  |  1.797 |      12.160      |      19.379      |
| Veteran                          | Non-Veteran |   2.150  |  1.698 |      -1.255      |       5.480      |
|                                  | Veteran     |  -2.150  |  1.698 |      -5.512      |       1.224      |
| Pre Score                        |             |   0.332  |  0.232 |      -0.132      |       0.800      |

## 5.2. Assumptions 

For the ANCOVA, there are the following assumptions: 

- Linearity
- Homogeneity of regression slopes
- Normality of residuals

Next, we are going to test these assumptions.

There appears to be a linear relationship between pre-test and post-test CAPS score for each group, as assessed by visual inspection of a scatter plot.

```{r}
# homogeneity of regression slopes
summary(lm(post_score ~ pre_score * veteran, data = vet))
```

From the non-significance of the interaction term, the homogeneity of regression slopes assumption appears to hold. This is also supported by a visual inspection from the figure above.  

```{r}
# normality of residuals
model <- lm(post_score ~ pre_score + veteran, data = vet)
plot(model, which = 2)
```

The QQ plot shows that the normality of residuals holds. There is a slight deviation at the tails, but this is often the case in practice. 